2023-06-09 03:00:23,073 -  - DEBUG - Filename: /Users/Dominik/University/Ljubljana/Courses/bigdata/project/Big-Data-Project-LJ/src/models/train_model.py


2023-06-09 03:00:23,073 -  - DEBUG - Line #    Mem usage    Increment  Occurrences   Line Contents

2023-06-09 03:00:23,074 -  - DEBUG - =============================================================

2023-06-09 03:00:23,074 -  - DEBUG -    198    316.6 MiB    316.6 MiB           1   @profile(stream=dask_ml_fh)

2023-06-09 03:00:23,074 -  - DEBUG -    199                                         def train_dask_ml_model2(X_train_dda, X_test_dda, y_train_dda, y_test_dda, classes):

2023-06-09 03:00:23,074 -  - DEBUG -    200    316.6 MiB      0.0 MiB           1       start_time = time.time()

2023-06-09 03:00:23,074 -  - DEBUG -    201                                             

2023-06-09 03:00:23,074 -  - DEBUG -    202    316.6 MiB      0.0 MiB           1       sgd = SGDClassifier(loss='log_loss')

2023-06-09 03:00:23,074 -  - DEBUG -    203                                         

2023-06-09 03:00:23,074 -  - DEBUG -    204    316.6 MiB      0.0 MiB           1       model = Incremental(sgd)

2023-06-09 03:00:23,074 -  - DEBUG -    205                                         

2023-06-09 03:00:23,074 -  - DEBUG -    206                                             #for X_batch, y_batch in data_chunker(X_train_dda, y_train_dda, chunk_size=1000):

2023-06-09 03:00:23,074 -  - DEBUG -    207                                                 #model.fit(X_batch, y_batch, classes=classes)

2023-06-09 03:00:23,074 -  - DEBUG -    208    316.6 MiB      0.0 MiB           1       print(type(X_train_dda))

2023-06-09 03:00:23,074 -  - DEBUG -    209    316.6 MiB      0.0 MiB           1       print(type(y_train_dda))

2023-06-09 03:00:23,074 -  - DEBUG -    210    316.9 MiB      0.3 MiB           1       model.fit(X=X_train_dda, y=y_train_dda, classes=classes)

2023-06-09 03:00:23,074 -  - DEBUG -    211    317.0 MiB      0.1 MiB           1       pred = model.predict(X_test_dda)

2023-06-09 03:00:23,074 -  - DEBUG -    212                                         

2023-06-09 03:00:23,074 -  - DEBUG -    213    317.1 MiB      0.1 MiB           1       accuracy = accuracy_score(y_test_dda.compute(), pred.compute())

2023-06-09 03:00:23,074 -  - DEBUG -    214    317.1 MiB      0.0 MiB           1       print("Dask-ML Model Accuracy: ", accuracy)

2023-06-09 03:00:23,074 -  - DEBUG -    215                                         

2023-06-09 03:00:23,074 -  - DEBUG -    216    317.1 MiB      0.0 MiB           1       pred_proba = model.predict_proba(X_test_dda)

2023-06-09 03:00:23,075 -  - DEBUG -    217    317.2 MiB      0.1 MiB           1       loss = log_loss(y_test_dda.compute(), pred_proba.compute())

2023-06-09 03:00:23,075 -  - DEBUG -    218    317.2 MiB      0.0 MiB           1       print("Dask-ML Model Log Loss: ", loss)

2023-06-09 03:00:23,075 -  - DEBUG -    219                                         

2023-06-09 03:00:23,075 -  - DEBUG -    220    317.2 MiB      0.0 MiB           1       sgd_model = model.estimator

2023-06-09 03:00:23,075 -  - DEBUG -    221    317.2 MiB      0.0 MiB           1       dump(sgd_model, '../../models/sgd_model.joblib')

2023-06-09 03:00:23,075 -  - DEBUG -    222                                         

2023-06-09 03:00:23,075 -  - DEBUG -    223    317.2 MiB      0.0 MiB           1       end_time = time.time()

2023-06-09 03:00:23,075 -  - DEBUG -    224    317.2 MiB      0.0 MiB           1       total_time = end_time - start_time

2023-06-09 03:00:23,075 -  - DEBUG -    225    317.2 MiB      0.0 MiB           1       print(f"Total time taken for Dask-ML model training: {total_time} seconds")

2023-06-09 03:00:23,075 -  - DEBUG -    226                                         

2023-06-09 03:00:23,075 -  - DEBUG -    227    317.2 MiB      0.0 MiB           1       logger = logging.getLogger('metrics_log')

2023-06-09 03:00:23,075 -  - DEBUG -    228    317.2 MiB      0.0 MiB           1       logger.setLevel(logging.INFO)

2023-06-09 03:00:23,076 -  - DEBUG -    229    317.2 MiB      0.0 MiB           1       fh = logging.FileHandler("../../reports/logs/dask_ml_metrics.log")

2023-06-09 03:00:23,076 -  - DEBUG -    230    317.2 MiB      0.0 MiB           1       fh.setLevel(logging.INFO)

2023-06-09 03:00:23,076 -  - DEBUG -    231    317.2 MiB      0.0 MiB           1       formatter = logging.Formatter('%(asctime)s - %(message)s')

2023-06-09 03:00:23,076 -  - DEBUG -    232    317.2 MiB      0.0 MiB           1       fh.setFormatter(formatter)

2023-06-09 03:00:23,076 -  - DEBUG -    233    317.2 MiB      0.0 MiB           1       logger.addHandler(fh)

2023-06-09 03:00:23,076 -  - DEBUG -    234    317.2 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Accuracy: {accuracy}")

2023-06-09 03:00:23,076 -  - DEBUG -    235    317.2 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Log Loss: {loss}")

2023-06-09 03:00:23,076 -  - DEBUG -    236    317.2 MiB      0.0 MiB           1       logger.info(f"Total time taken for Dask-ML model training: {total_time} seconds")

2023-06-09 03:00:23,076 -  - DEBUG -    237    317.2 MiB      0.0 MiB           1       logger.removeHandler(fh)

2023-06-09 03:00:23,076 -  - DEBUG - 


2023-07-04 14:48:18,121 -  - DEBUG - Filename: /Users/Dominik/University/Ljubljana/Courses/bigdata/project/Big-Data-Project-LJ/src/models/train_model.py


2023-07-04 14:48:18,122 -  - DEBUG - Line #    Mem usage    Increment  Occurrences   Line Contents

2023-07-04 14:48:18,122 -  - DEBUG - =============================================================

2023-07-04 14:48:18,122 -  - DEBUG -    300    361.9 MiB    361.9 MiB           1   @profile(stream=dask_ml_fh)

2023-07-04 14:48:18,122 -  - DEBUG -    301                                         def train_dask_ml_model2(X_train, X_val, X_test, y_train, y_val, y_test, classes):

2023-07-04 14:48:18,122 -  - DEBUG -    302    361.9 MiB      0.0 MiB           1       start_time = time.time()

2023-07-04 14:48:18,122 -  - DEBUG -    303                                             

2023-07-04 14:48:18,122 -  - DEBUG -    304    361.9 MiB      0.0 MiB           1       sgd = SGDClassifier(loss='log') # Changed from 'log_loss' to 'log' which is a valid loss option for SGDClassifier

2023-07-04 14:48:18,122 -  - DEBUG -    305                                         

2023-07-04 14:48:18,122 -  - DEBUG -    306    361.9 MiB      0.0 MiB           1       model = Incremental(sgd)

2023-07-04 14:48:18,122 -  - DEBUG -    307                                         

2023-07-04 14:48:18,122 -  - DEBUG -    308    361.9 MiB      0.0 MiB           1       print(type(X_train))

2023-07-04 14:48:18,123 -  - DEBUG -    309    361.9 MiB      0.0 MiB           1       print(type(y_train))

2023-07-04 14:48:18,123 -  - DEBUG -    310    362.1 MiB      0.3 MiB           1       model.fit(X=X_train, y=y_train, classes=classes)

2023-07-04 14:48:18,123 -  - DEBUG -    311                                         

2023-07-04 14:48:18,123 -  - DEBUG -    312                                             # Compute predictions for train, validation, and test datasets

2023-07-04 14:48:18,123 -  - DEBUG -    313    362.2 MiB      0.0 MiB           1       y_train_pred = model.predict(X_train)

2023-07-04 14:48:18,123 -  - DEBUG -    314    362.2 MiB      0.0 MiB           1       y_val_pred = model.predict(X_val)

2023-07-04 14:48:18,123 -  - DEBUG -    315    362.2 MiB      0.0 MiB           1       y_test_pred = model.predict(X_test)

2023-07-04 14:48:18,123 -  - DEBUG -    316                                         

2023-07-04 14:48:18,123 -  - DEBUG -    317                                             # Compute accuracy for train, validation, and test datasets

2023-07-04 14:48:18,123 -  - DEBUG -    318    362.3 MiB      0.1 MiB           1       train_accuracy = accuracy_score(y_train.compute(), y_train_pred.compute())

2023-07-04 14:48:18,123 -  - DEBUG -    319    362.4 MiB      0.1 MiB           1       val_accuracy = accuracy_score(y_val.compute(), y_val_pred.compute())

2023-07-04 14:48:18,123 -  - DEBUG -    320    362.5 MiB      0.1 MiB           1       test_accuracy = accuracy_score(y_test.compute(), y_test_pred.compute())

2023-07-04 14:48:18,123 -  - DEBUG -    321                                         

2023-07-04 14:48:18,123 -  - DEBUG -    322                                             # Compute precision and recall for test dataset

2023-07-04 14:48:18,123 -  - DEBUG -    323    362.5 MiB      0.0 MiB           1       test_precision = precision_score(y_test.compute(), y_test_pred.compute())

2023-07-04 14:48:18,123 -  - DEBUG -    324    362.5 MiB      0.0 MiB           1       test_recall = recall_score(y_test.compute(), y_test_pred.compute())

2023-07-04 14:48:18,123 -  - DEBUG -    325                                         

2023-07-04 14:48:18,123 -  - DEBUG -    326                                             # Compute log loss for train, validation, and test datasets

2023-07-04 14:48:18,123 -  - DEBUG -    327    362.5 MiB      0.0 MiB           1       y_train_pred_proba = model.predict_proba(X_train)

2023-07-04 14:48:18,124 -  - DEBUG -    328    362.6 MiB      0.0 MiB           1       y_val_pred_proba = model.predict_proba(X_val)

2023-07-04 14:48:18,124 -  - DEBUG -    329    362.6 MiB      0.0 MiB           1       y_test_pred_proba = model.predict_proba(X_test)

2023-07-04 14:48:18,124 -  - DEBUG -    330                                         

2023-07-04 14:48:18,124 -  - DEBUG -    331    362.6 MiB      0.1 MiB           1       train_loss = log_loss(y_train.compute(), y_train_pred_proba.compute())

2023-07-04 14:48:18,124 -  - DEBUG -    332    362.7 MiB      0.0 MiB           1       val_loss = log_loss(y_val.compute(), y_val_pred_proba.compute())

2023-07-04 14:48:18,124 -  - DEBUG -    333    362.7 MiB      0.1 MiB           1       test_loss = log_loss(y_test.compute(), y_test_pred_proba.compute())

2023-07-04 14:48:18,124 -  - DEBUG -    334                                         

2023-07-04 14:48:18,124 -  - DEBUG -    335    362.8 MiB      0.0 MiB           1       print("Dask-ML Model Train Accuracy: ", train_accuracy)

2023-07-04 14:48:18,124 -  - DEBUG -    336    362.8 MiB      0.0 MiB           1       print("Dask-ML Model Train Log Loss: ", train_loss)

2023-07-04 14:48:18,124 -  - DEBUG -    337    362.8 MiB      0.0 MiB           1       print("Dask-ML Model Validation Accuracy: ", val_accuracy)

2023-07-04 14:48:18,124 -  - DEBUG -    338    362.8 MiB      0.0 MiB           1       print("Dask-ML Model Validation Log Loss: ", val_loss)

2023-07-04 14:48:18,124 -  - DEBUG -    339    362.8 MiB      0.0 MiB           1       print("Dask-ML Model Test Accuracy: ", test_accuracy)

2023-07-04 14:48:18,124 -  - DEBUG -    340    362.8 MiB      0.0 MiB           1       print("Dask-ML Model Test Precision: ", test_precision)

2023-07-04 14:48:18,124 -  - DEBUG -    341    362.8 MiB      0.0 MiB           1       print("Dask-ML Model Test Recall: ", test_recall)

2023-07-04 14:48:18,124 -  - DEBUG -    342    362.8 MiB      0.0 MiB           1       print("Dask-ML Model Test Log Loss: ", test_loss)

2023-07-04 14:48:18,124 -  - DEBUG -    343                                         

2023-07-04 14:48:18,124 -  - DEBUG -    344    362.8 MiB      0.0 MiB           1       sgd_model = model.estimator

2023-07-04 14:48:18,124 -  - DEBUG -    345    362.8 MiB      0.0 MiB           1       dump(sgd_model, '../../models/sgd_model.joblib')

2023-07-04 14:48:18,124 -  - DEBUG -    346                                         

2023-07-04 14:48:18,124 -  - DEBUG -    347    362.8 MiB      0.0 MiB           1       end_time = time.time()

2023-07-04 14:48:18,124 -  - DEBUG -    348    362.8 MiB      0.0 MiB           1       total_time = end_time - start_time

2023-07-04 14:48:18,124 -  - DEBUG -    349    362.8 MiB      0.0 MiB           1       print(f"Total time taken for Dask-ML model training: {total_time} seconds")

2023-07-04 14:48:18,124 -  - DEBUG -    350                                         

2023-07-04 14:48:18,124 -  - DEBUG -    351                                             # Log the metrics

2023-07-04 14:48:18,124 -  - DEBUG -    352    362.8 MiB      0.0 MiB           1       logger = logging.getLogger('metrics_log')

2023-07-04 14:48:18,125 -  - DEBUG -    353    362.8 MiB      0.0 MiB           1       logger.setLevel(logging.INFO)

2023-07-04 14:48:18,125 -  - DEBUG -    354    362.8 MiB      0.0 MiB           1       fh = logging.FileHandler("../../reports/logs/dask_ml_metrics.log")

2023-07-04 14:48:18,125 -  - DEBUG -    355    362.8 MiB      0.0 MiB           1       fh.setLevel(logging.INFO)

2023-07-04 14:48:18,125 -  - DEBUG -    356    362.8 MiB      0.0 MiB           1       formatter = logging.Formatter('%(asctime)s - %(message)s')

2023-07-04 14:48:18,125 -  - DEBUG -    357    362.8 MiB      0.0 MiB           1       fh.setFormatter(formatter)

2023-07-04 14:48:18,125 -  - DEBUG -    358    362.8 MiB      0.0 MiB           1       logger.addHandler(fh)

2023-07-04 14:48:18,125 -  - DEBUG -    359    362.8 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Train Accuracy: {train_accuracy}")

2023-07-04 14:48:18,125 -  - DEBUG -    360    362.8 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Train Log Loss: {train_loss}")

2023-07-04 14:48:18,125 -  - DEBUG -    361    362.8 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Validation Accuracy: {val_accuracy}")

2023-07-04 14:48:18,125 -  - DEBUG -    362    362.8 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Validation Log Loss: {val_loss}")

2023-07-04 14:48:18,125 -  - DEBUG -    363    362.8 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Test Accuracy: {test_accuracy}")

2023-07-04 14:48:18,125 -  - DEBUG -    364    362.8 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Test Precision: {test_precision}")

2023-07-04 14:48:18,125 -  - DEBUG -    365    362.8 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Test Recall: {test_recall}")

2023-07-04 14:48:18,125 -  - DEBUG -    366    362.8 MiB      0.0 MiB           1       logger.info(f"Dask-ML Model Test Log Loss: {test_loss}")

2023-07-04 14:48:18,125 -  - DEBUG -    367    362.8 MiB      0.0 MiB           1       logger.info(f"Total time taken for Dask-ML model training: {total_time} seconds")

2023-07-04 14:48:18,125 -  - DEBUG -    368    362.8 MiB      0.0 MiB           1       logger.removeHandler(fh)

2023-07-04 14:48:18,125 -  - DEBUG -    369                                         

2023-07-04 14:48:18,125 -  - DEBUG -    370                                             # Create bar plots for the loss and accuracy metrics

2023-07-04 14:48:18,125 -  - DEBUG -    371    363.3 MiB      0.5 MiB           1       plt.figure(figsize=(10, 5))

2023-07-04 14:48:18,125 -  - DEBUG -    372    363.5 MiB      0.2 MiB           1       plt.bar(['Train', 'Validation', 'Test'], [train_loss, val_loss, test_loss], color=['blue', 'orange', 'green'])

2023-07-04 14:48:18,125 -  - DEBUG -    373    363.5 MiB      0.0 MiB           1       plt.ylabel('Log Loss')

2023-07-04 14:48:18,125 -  - DEBUG -    374    363.5 MiB      0.0 MiB           1       plt.title('SGD Log Loss')

2023-07-04 14:48:18,126 -  - DEBUG -    375    365.7 MiB      2.2 MiB           1       plt.savefig('../../reports/figures/sgd_log_loss.png')

2023-07-04 14:48:18,126 -  - DEBUG -    376                                         

2023-07-04 14:48:18,126 -  - DEBUG -    377    366.0 MiB      0.4 MiB           1       plt.figure(figsize=(10, 5))

2023-07-04 14:48:18,126 -  - DEBUG -    378    366.3 MiB      0.3 MiB           1       plt.bar(['Train', 'Validation', 'Test'], [train_accuracy, val_accuracy, test_accuracy], color=['blue', 'orange', 'green'])

2023-07-04 14:48:18,126 -  - DEBUG -    379    366.3 MiB      0.0 MiB           1       plt.ylabel('Accuracy')

2023-07-04 14:48:18,126 -  - DEBUG -    380    366.3 MiB      0.0 MiB           1       plt.title('SGD Accuracy')

2023-07-04 14:48:18,126 -  - DEBUG -    381    368.6 MiB      2.3 MiB           1       plt.savefig('../../reports/figures/sgd_accuracy.png')

2023-07-04 14:48:18,126 -  - DEBUG -    382                                         

2023-07-04 14:48:18,126 -  - DEBUG -    383                                             # creating figures for the metrics and saving them

2023-07-04 14:48:18,126 -  - DEBUG -    384    368.6 MiB      0.0 MiB           1       metrics = [test_accuracy, test_precision, test_recall, test_loss]

2023-07-04 14:48:18,126 -  - DEBUG -    385    368.6 MiB      0.0 MiB           1       metric_names = ['Accuracy', 'Precision', 'Recall', 'Log Loss']

2023-07-04 14:48:18,126 -  - DEBUG -    386                                         

2023-07-04 14:48:18,126 -  - DEBUG -    387    368.8 MiB      0.2 MiB           1       plt.figure(figsize=(10, 5))

2023-07-04 14:48:18,126 -  - DEBUG -    388    369.1 MiB      0.3 MiB           1       plt.bar(metric_names, metrics, color=['blue', 'orange', 'green', 'red'])

2023-07-04 14:48:18,126 -  - DEBUG -    389    369.1 MiB      0.0 MiB           5       for i in range(len(metrics)):

2023-07-04 14:48:18,127 -  - DEBUG -    390    369.1 MiB      0.0 MiB           4           plt.text(i, metrics[i], round(metrics[i], 2), ha='center')

2023-07-04 14:48:18,127 -  - DEBUG -    391    371.4 MiB      2.3 MiB           1       plt.savefig('../../reports/figures/SGD_metrics_bar_chart.png')

2023-07-04 14:48:18,127 -  - DEBUG - 


